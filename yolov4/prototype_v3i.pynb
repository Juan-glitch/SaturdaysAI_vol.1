{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv4-tiny: DISTANCE DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import jit,float32\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "\n",
    "cv2. __version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.publish as publish\n",
    "import paho.mqtt.client as mqtt\n",
    "import ssl\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "BROKER_ADDRESS = '127.0.0.1'\n",
    "PORT = 1883\n",
    "ID = 'WATCHDOG'\n",
    "TOPIC= ['DATA','IMG']\n",
    "#In case TCP is not enought\n",
    "# https://pypi.org/project/paho-mqtt/#subscribe-unsubscribe\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(f'connected ID: {client._client_id}')\n",
    "    client.subscribe(topic=TOPIC_SUSCRIBE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT ALGORITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Func_net = cv2.dnn.readNet( weights_file,cfgfile)\n",
    "net = cv2.dnn.readNet(\"yolov4-tiny.weights\", \"yolov4_tiny.cfg\")\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]        \n",
    "colors = np.random.uniform(0,255, size=(len(classes),3))\n",
    "font =cv2.FONT_HERSHEY_PLAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True) # +3 FPS   \n",
    "def PERSON_FLTR_1(OUTS, THRESHOLD, H,W):\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    \n",
    "    for out in OUTS:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            \n",
    "            # PERSON DETECTED\n",
    "            if (confidence > THRESHOLD) and class_id == 0: \n",
    "\n",
    "                center_x = int(detection[0]*W) \n",
    "                #from the bounding box to the center\n",
    "                center_y = int(detection[1]*H) \n",
    "                #from the bb to cy\n",
    "                w = int(detection[2]*W)\n",
    "                h = int(detection[3]*H)\n",
    "                \n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                \n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                centroids.append((center_x,center_y))\n",
    "                \n",
    "                \n",
    "    return   class_ids,confidences, boxes, centroids \n",
    "\n",
    "\n",
    "def PERSON_FLTR_2(IDX,ID,CONF, BB, CENTROIDS):\n",
    "    \n",
    "    results = []\n",
    "    # loop over the indexes we are keeping\n",
    "    for i in IDX.flatten():\n",
    "        # extract the bounding box coordinates\n",
    "        (x, y) = (BB[i][0], BB[i][1])\n",
    "        (w, h) = (BB[i][2], BB[i][3])\n",
    "        # update our results list to consist of the person\n",
    "        # prediction probability, bounding box coordinates,\n",
    "        # and the centroid\n",
    "        r = (CONF[i], (x, y, x + w, y + h), CENTROIDS[i])\n",
    "        results.append(r)\n",
    "    # return the list of results\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START CAPTURING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.3909917869216\n",
      "183.63550854886427\n",
      "172.45579143653018\n",
      "168.51409436602032\n",
      "168.1814496310458\n",
      "172.53985046939155\n",
      "168.8697723099075\n",
      "173.21951391226105\n",
      "174.4161689752415\n",
      "199.84243793548956\n",
      "196.1479033790573\n",
      "189.84203960134857\n",
      "191.23022773609824\n",
      "189.45184084616332\n",
      "187.7471704180918\n",
      "188.09837851507388\n",
      "188.47015678881365\n",
      "188.47015678881365\n",
      "191.049731745428\n",
      "189.88944151795275\n",
      "190.87430418995638\n",
      "191.68985366993215\n",
      "187.2591786802452\n",
      "188.403821617291\n",
      "190.07366992826755\n",
      "190.87430418995638\n",
      "189.71821209362056\n",
      "190.22355269524328\n",
      "187.57931655702342\n",
      "190.53870997778904\n",
      "192.67589366602144\n",
      "192.03385118254542\n",
      "191.68985366993215\n",
      "190.70395905696347\n",
      "190.87430418995638\n",
      "190.06577808748213\n",
      "192.03385118254542\n",
      "188.47015678881365\n",
      "191.68985366993215\n",
      "187.29922583929704\n",
      "187.7471704180918\n",
      "187.29922583929704\n",
      "186.50737250843463\n",
      "189.84203960134857\n",
      "191.049731745428\n",
      "191.23022773609824\n",
      "190.06577808748213\n",
      "193.0181338631166\n",
      "191.68985366993215\n",
      "193.49935400408964\n",
      "195.63486396856774\n",
      "188.904737897174\n",
      "189.64440408301004\n",
      "187.29922583929704\n",
      "189.2643653728826\n",
      "186.4296113818832\n",
      "189.88944151795275\n",
      "190.87430418995638\n",
      "186.50737250843463\n",
      "184.5453873712372\n",
      "182.7840255602223\n",
      "182.8879438344693\n",
      "189.67603960437387\n",
      "190.7590102721232\n",
      "193.58202395883765\n",
      "198.8164983093707\n",
      "198.56736892047493\n",
      "199.42417105255822\n",
      "190.4442175546425\n",
      "189.04232330353963\n",
      "176.28386199536246\n",
      "176.40861656959956\n",
      "177.28226081590904\n",
      "196.1249601657066\n",
      "177.40631330367023\n",
      "178.2806775845324\n",
      "158.00316452527144\n",
      "159.0125781188394\n",
      "194.0025773024678\n",
      "194.0\n"
     ]
    }
   ],
   "source": [
    "# define the minimum safe distance (in pixels) that two people can be\n",
    "# from each other\n",
    "MIN_DISTANCE = 200 # Test/Error\n",
    "n = 0 #camera\n",
    "THRESHOLD = 0.4\n",
    "H, W = 480,640\n",
    "cap = cv2.VideoCapture(n)#0 for the first webcam and 1 for the second one\n",
    "                        #...and if we want just put a video folder here\n",
    "#GET FRAMES IN REAL TIME:\n",
    "start_time = time.time() #colect start time\n",
    "frame_id = 0 #colects frame quanty\n",
    "\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    frame_id += 1\n",
    "    # PARA SABER RESOLUCIÃ“N JETSON  = > height, width, _ = frame.shape\n",
    "    \n",
    "    #Standard Yolo Size 320x 320 /416 x 416\n",
    "    # Function = blobFromImage(imag, scale_factor, size,mean*, swapRB*, crop) \n",
    "    blob = cv2.dnn.blobFromImage(frame, (1 / 255.0),\n",
    "                                 (320,320),(0,0,0), True, crop = False)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    # 2 Detections (300, 85) / (1200, 85)    \n",
    "    OUTS = net.forward(output_layers)\n",
    "    \n",
    "    class_ids,confidences, boxes, centroids = PERSON_FLTR_1(OUTS, THRESHOLD, H,W)\n",
    "\n",
    "                \n",
    "    #NON MAX SUPRESSION\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6,0.5)\n",
    "    # initialize the set of indexes that violate the minimum social\n",
    "    # distance\n",
    "    violate = set()\n",
    "\n",
    "    # if not this...error\n",
    "    if len(indexes) > 0:\n",
    "        results = PERSON_FLTR_2(indexes,class_ids,confidences, boxes, centroids)\n",
    "        \n",
    "        if len(results) >= 2:\n",
    "            # extract all centroids from the results and compute the\n",
    "            # Euclidean distances between all pairs of the centroids\n",
    "            centroids = np.array([r[2] for r in results])\n",
    "            D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "            #Dpatch = D[0]\n",
    "            #Dpatch = centroids - centroids\n",
    "            # loop over the upper triangular of the distance matrix\n",
    "            for i in range(0, D.shape[0]):\n",
    "                for j in range(i + 1, D.shape[1]):\n",
    "                    # check to see if the distance between any two\n",
    "                    # centroid pairs is less than the configured number\n",
    "                    # of pixels\n",
    "                    Dpatch = np.amax(D[i, j]) # Error in calculous\n",
    "                    if Dpatch < MIN_DISTANCE:\n",
    "                        # UPDATE VIOLATIONS\n",
    "                        violate.add(i)\n",
    "                        violate.add(j)\n",
    "                        # FLAG TO SAVE IMAGE\n",
    "                      \n",
    "        # loop over the results\n",
    "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "            # extract the bounding box and centroid coordinates, then\n",
    "            # initialize the color of the annotation\n",
    "            (startX, startY, endX, endY) = bbox\n",
    "            (cX, cY) = centroid.amax(arr)\n",
    "            color = (0, 255, 0)\n",
    "            # if the index pair exists within the violation set, then\n",
    "            # update the color\n",
    "            if i in violate:\n",
    "                color = (0, 0, 255)\n",
    "            # draw (1) a bounding box around the person and (2) the\n",
    "            # centroid coordinates of the person,\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "            cv2.circle(frame, (cX, cY), 3, (90,0,252), 2)\n",
    "        # draw the total number of social distancing violations on the\n",
    "        # output frame\n",
    "        text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "        cv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    #SPEED TESTER\n",
    "    elapse = time.time()- start_time  \n",
    "    \n",
    "    fps = frame_id/elapse\n",
    "    #function_putText = (img, text, org, fontFace, fontScale, color, thikness, lineType, botonLeft)\n",
    "    cv2.putText( frame, \"FPS: \" + str(round(fps,2)),(10,30), font, 3,(0,255,0),1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #OUTPUT IMAGE\n",
    "    cv2.imshow(\"Scratch_YOLO_CV_2.1\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #STOP COMMANDS\n",
    "    if key == 27: #esc keyboard\n",
    "        break\n",
    "    \n",
    "cap.release() #Close camera reading\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[  0.         355.48558339]\n",
    "[  0.         357.46328483]\n",
    "[  0.         360.72149922]\n",
    "[  0.         351.64328516]\n",
    "[  0.         345.21008097]\n",
    "[  0.        342.5842962]\n",
    "[  0.         345.05072091]\n",
    "[  0.         370.64808107]\n",
    "[  0.         335.43106594]\n",
    "[  0.         373.28005572]\n",
    "[  0.         378.14415241]\n",
    "[  0.         375.20261193]\n",
    "[  0.         378.33979436]\n",
    "[  0.         374.85597234]\n",
    "[  0.         373.03351056]\n",
    "[  0.         374.42889846]\n",
    "[  0.         367.16481313]\n",
    "[  0.         369.28715114]\n",
    "[  0.         377.52483362]\n",
    "[  0.         372.82837875]\n",
    "[  0.         369.48612964]\n",
    "[  0.         374.97733265]\n",
    "[  0.         372.82837875]\n",
    "[  0.         374.78660595]\n",
    "[  0.         375.56490784]\n",
    "[  0.         386.54495211]\n",
    "[  0.         376.94827231]\n",
    "[  0.         336.36438575]\n",
    "[  0.       331.834296]\n",
    "[  0.         372.63386856]\n",
    "[  0.         375.36648758]\n",
    "[  0.         365.95354896]\n",
